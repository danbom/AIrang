{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aitextgen_GPT2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"be228154ccc04a9aa6693be580631883":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b1a35b10abe4fd9b104a8201945c820","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b265234f8f5f472d8083b22ef8ea632b","IPY_MODEL_ff61c3f3d5264647afe29c7afb4bdfc1"]}},"1b1a35b10abe4fd9b104a8201945c820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b265234f8f5f472d8083b22ef8ea632b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_62ed24491280415dbf0ece30145705a8","_dom_classes":[],"description":"Fetching checkpoint: ","_model_name":"FloatProgressModel","bar_style":"success","max":77,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89129d098f384c25bdc44faea24ffbe4"}},"ff61c3f3d5264647afe29c7afb4bdfc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f99be79a99df4fd18d75cde02b26aff7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.05M/? [00:07&lt;00:00, 149kit/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b22eb163e1294c6b9ef3fd88f9f6446b"}},"62ed24491280415dbf0ece30145705a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"89129d098f384c25bdc44faea24ffbe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f99be79a99df4fd18d75cde02b26aff7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b22eb163e1294c6b9ef3fd88f9f6446b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77b5928857a2450cb81edf951e4fc899":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_90ed5d3206804039ad7faaef2fcca723","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ced9653e879b41c78b44e4909f7a9953","IPY_MODEL_8170360aebc94c80858325bd2c424bad"]}},"90ed5d3206804039ad7faaef2fcca723":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ced9653e879b41c78b44e4909f7a9953":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_718e279b5c6d47f681da97475fc16009","_dom_classes":[],"description":"Fetching hparams.json: ","_model_name":"FloatProgressModel","bar_style":"success","max":90,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":90,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ccae8747f7384bdcaebf66832b3acb10"}},"8170360aebc94c80858325bd2c424bad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1402d3008ca4441b8fd22ebd19ae911a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.05M/? [00:06&lt;00:00, 150kit/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f146da374aa5464ea8e46486623ae482"}},"718e279b5c6d47f681da97475fc16009":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ccae8747f7384bdcaebf66832b3acb10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1402d3008ca4441b8fd22ebd19ae911a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f146da374aa5464ea8e46486623ae482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e76480361f1c472db48054fa06cca126":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_106d5f15fee1407c8dc2a83c7adda866","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_abb8615cd10543bcb74fa1374ade2919","IPY_MODEL_74c15f910b744ce89f176566a9cc2a0e"]}},"106d5f15fee1407c8dc2a83c7adda866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abb8615cd10543bcb74fa1374ade2919":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ee76795d35404ab1913bdb27466f2b62","_dom_classes":[],"description":"Fetching model.ckpt.data-00000-of-00001: ","_model_name":"FloatProgressModel","bar_style":"success","max":497759232,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":497759232,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a432495aa6c84365a23907e43968218d"}},"74c15f910b744ce89f176566a9cc2a0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69f9b99012994a9a93e2be56e043decb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 498M/? [00:04&lt;00:00, 124Mit/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c51162fdf5744b669107332bba1ed56c"}},"ee76795d35404ab1913bdb27466f2b62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a432495aa6c84365a23907e43968218d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69f9b99012994a9a93e2be56e043decb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c51162fdf5744b669107332bba1ed56c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"911394377ae14321af70eef6cc685f76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_abb0843a65c84ee3a2ceaf0a5a0d3427","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ffe16e1a35ee40a2bc5139c4bda8f3ed","IPY_MODEL_cf2c56c757ec4848a27715fd58be6718"]}},"abb0843a65c84ee3a2ceaf0a5a0d3427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffe16e1a35ee40a2bc5139c4bda8f3ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3e05e08ccd3c435789b2f82fd4925517","_dom_classes":[],"description":"Fetching model.ckpt.index: ","_model_name":"FloatProgressModel","bar_style":"success","max":5215,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5215,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f0ea274ead8944808e0aaef3cd284a2f"}},"cf2c56c757ec4848a27715fd58be6718":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0bf6f90e31644e0fbe7ecca169933360","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.05M/? [00:00&lt;00:00, 13.9Mit/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8044a6d23e5c4b5f8c3f6e927022235c"}},"3e05e08ccd3c435789b2f82fd4925517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f0ea274ead8944808e0aaef3cd284a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bf6f90e31644e0fbe7ecca169933360":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8044a6d23e5c4b5f8c3f6e927022235c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b56d0a4263ac4125a8fcee19363e5e04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_63e5b6171d804bc288b232e260168b16","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8af47a8325504027bd052e7b824ba935","IPY_MODEL_d95aae6291e64f16b34e75594bce88d8"]}},"63e5b6171d804bc288b232e260168b16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8af47a8325504027bd052e7b824ba935":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f180d9da5f104bf4ae7c54ce4902181f","_dom_classes":[],"description":"Fetching model.ckpt.meta: ","_model_name":"FloatProgressModel","bar_style":"success","max":471155,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":471155,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79104f5f62664dc897e1e0c6e2da688d"}},"d95aae6291e64f16b34e75594bce88d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc1ccbde00264fe9b98f8cd1e8609313","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.05M/? [00:02&lt;00:00, 370kit/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_813b54dde446438c85d21dd1899cc569"}},"f180d9da5f104bf4ae7c54ce4902181f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"79104f5f62664dc897e1e0c6e2da688d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc1ccbde00264fe9b98f8cd1e8609313":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"813b54dde446438c85d21dd1899cc569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"H7LoMj4GA4n_"},"source":["#  aitextgen — Train a GPT-2 Text-Generating Model w/ GPU\n","\n","by [Max Woolf](https://minimaxir.com)\n","\n","*Last updated: Jul 5th, 2020*\n","\n","Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Colaboratory** using `aitextgen`!\n","\n","For more about `aitextgen`, you can visit [this GitHub repository](https://github.com/minimaxir/aitextgen) or [read the documentation](https://docs.aitextgen.io/).\n","\n","\n","To get started:\n","\n","1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n","2. Run the cells below:\n","*** 이전 사용 코드: https://github.com/YeonwooSung/KoGPT2_Lyricist/tree/master/src"]},{"cell_type":"code","metadata":{"id":"KBkpRgBCBS2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612410849065,"user_tz":-540,"elapsed":32234,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"c67d311c-c6b9-45c2-fd7f-49b61a09a9e5"},"source":["# !pip install -q aitextgen\n","\n","!pip install -q transformers>=4.0.0\n","!pip install -q fire>=0.3.0\n","!pip install -q pytorch-lightning>=1.0.8\n","!pip install -q tokenizers>=1.0.0\n","!pip install -q torch>=1.6.0\n","!pip install -q aitextgen --no-deps\n","\n","import logging\n","logging.basicConfig(\n","        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO\n","    )\n","\n","from aitextgen import aitextgen\n","from aitextgen.colab import mount_gdrive, copy_file_from_gdrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▋                               | 10kB 33.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 501kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 512kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 522kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 532kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 542kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 552kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 563kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 8.1MB/s \n","\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bj2IJLHP3KwE"},"source":["## GPU\n","\n","Colaboratory uses a Nvidia P4, an Nvidia T4, or an Nvidia P100 GPU. For finetuning GPT-2 124M, any of these GPUs will be fine, but for text generation, a T4 or a P100 is ideal since they have more VRAM.\n","\n","You can verify which GPU is active by running the cell below. If you want to try for a different GPU, go to **Runtime -> Factory Reset Runtime**."]},{"cell_type":"code","metadata":{"id":"sUmTooTW3osf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612410849077,"user_tz":-540,"elapsed":32214,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"c35f301c-ebd4-45a5-b7fc-2e3de7405a23"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Feb  4 03:54:08 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   61C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"trRhgNvsH4Wn"},"source":["## Loading GPT-2\n","\n","If you're retraining a model on new text, you need to download and load the GPT-2 model into the GPU. \n","\n","There are several sizes of GPT-2: currently, aitextgen only works with the smallest one:\n","\n","* `124M` (default): the \"small\" model, 500MB on disk.\n","\n","The next cell downloads it from Google's servers and saves it in the Colaboratory VM. If the model has already been downloaded, running this cell will reload it."]},{"cell_type":"code","metadata":{"id":"flqSlHjMIeIw","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["be228154ccc04a9aa6693be580631883","1b1a35b10abe4fd9b104a8201945c820","b265234f8f5f472d8083b22ef8ea632b","ff61c3f3d5264647afe29c7afb4bdfc1","62ed24491280415dbf0ece30145705a8","89129d098f384c25bdc44faea24ffbe4","f99be79a99df4fd18d75cde02b26aff7","b22eb163e1294c6b9ef3fd88f9f6446b","77b5928857a2450cb81edf951e4fc899","90ed5d3206804039ad7faaef2fcca723","ced9653e879b41c78b44e4909f7a9953","8170360aebc94c80858325bd2c424bad","718e279b5c6d47f681da97475fc16009","ccae8747f7384bdcaebf66832b3acb10","1402d3008ca4441b8fd22ebd19ae911a","f146da374aa5464ea8e46486623ae482","e76480361f1c472db48054fa06cca126","106d5f15fee1407c8dc2a83c7adda866","abb8615cd10543bcb74fa1374ade2919","74c15f910b744ce89f176566a9cc2a0e","ee76795d35404ab1913bdb27466f2b62","a432495aa6c84365a23907e43968218d","69f9b99012994a9a93e2be56e043decb","c51162fdf5744b669107332bba1ed56c","911394377ae14321af70eef6cc685f76","abb0843a65c84ee3a2ceaf0a5a0d3427","ffe16e1a35ee40a2bc5139c4bda8f3ed","cf2c56c757ec4848a27715fd58be6718","3e05e08ccd3c435789b2f82fd4925517","f0ea274ead8944808e0aaef3cd284a2f","0bf6f90e31644e0fbe7ecca169933360","8044a6d23e5c4b5f8c3f6e927022235c","b56d0a4263ac4125a8fcee19363e5e04","63e5b6171d804bc288b232e260168b16","8af47a8325504027bd052e7b824ba935","d95aae6291e64f16b34e75594bce88d8","f180d9da5f104bf4ae7c54ce4902181f","79104f5f62664dc897e1e0c6e2da688d","bc1ccbde00264fe9b98f8cd1e8609313","813b54dde446438c85d21dd1899cc569"]},"executionInfo":{"status":"ok","timestamp":1612410879025,"user_tz":-540,"elapsed":62138,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"362df9cd-b44a-4851-a1b5-406831a67374"},"source":["ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["02/04/2021 03:54:08 — INFO — aitextgen — Downloading the 124M GPT-2 TensorFlow weights/config from Google's servers\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be228154ccc04a9aa6693be580631883","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Fetching checkpoint', max=77.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77b5928857a2450cb81edf951e4fc899","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Fetching hparams.json', max=90.0, style=ProgressStyle(des…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e76480361f1c472db48054fa06cca126","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.data-00000-of-00001', max=497759232.0…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"911394377ae14321af70eef6cc685f76","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.index', max=5215.0, style=ProgressSty…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b56d0a4263ac4125a8fcee19363e5e04","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.meta', max=471155.0, style=ProgressSt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["02/04/2021 03:54:13 — INFO — aitextgen — Converting the 124M GPT-2 TensorFlow weights to PyTorch.\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Converting TensorFlow checkpoint from /content/aitextgen/124M\n","Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h0/attn/c_proj/b with shape [768]\n","Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h0/ln_1/b with shape [768]\n","Loading TF weight model/h0/ln_1/g with shape [768]\n","Loading TF weight model/h0/ln_2/b with shape [768]\n","Loading TF weight model/h0/ln_2/g with shape [768]\n","Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h1/attn/c_proj/b with shape [768]\n","Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h1/ln_1/b with shape [768]\n","Loading TF weight model/h1/ln_1/g with shape [768]\n","Loading TF weight model/h1/ln_2/b with shape [768]\n","Loading TF weight model/h1/ln_2/g with shape [768]\n","Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h10/attn/c_proj/b with shape [768]\n","Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h10/ln_1/b with shape [768]\n","Loading TF weight model/h10/ln_1/g with shape [768]\n","Loading TF weight model/h10/ln_2/b with shape [768]\n","Loading TF weight model/h10/ln_2/g with shape [768]\n","Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h11/attn/c_proj/b with shape [768]\n","Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h11/ln_1/b with shape [768]\n","Loading TF weight model/h11/ln_1/g with shape [768]\n","Loading TF weight model/h11/ln_2/b with shape [768]\n","Loading TF weight model/h11/ln_2/g with shape [768]\n","Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h2/attn/c_proj/b with shape [768]\n","Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h2/ln_1/b with shape [768]\n","Loading TF weight model/h2/ln_1/g with shape [768]\n","Loading TF weight model/h2/ln_2/b with shape [768]\n","Loading TF weight model/h2/ln_2/g with shape [768]\n","Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h3/attn/c_proj/b with shape [768]\n","Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h3/ln_1/b with shape [768]\n","Loading TF weight model/h3/ln_1/g with shape [768]\n","Loading TF weight model/h3/ln_2/b with shape [768]\n","Loading TF weight model/h3/ln_2/g with shape [768]\n","Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h4/attn/c_proj/b with shape [768]\n","Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h4/ln_1/b with shape [768]\n","Loading TF weight model/h4/ln_1/g with shape [768]\n","Loading TF weight model/h4/ln_2/b with shape [768]\n","Loading TF weight model/h4/ln_2/g with shape [768]\n","Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h5/attn/c_proj/b with shape [768]\n","Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h5/ln_1/b with shape [768]\n","Loading TF weight model/h5/ln_1/g with shape [768]\n","Loading TF weight model/h5/ln_2/b with shape [768]\n","Loading TF weight model/h5/ln_2/g with shape [768]\n","Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h6/attn/c_proj/b with shape [768]\n","Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h6/ln_1/b with shape [768]\n","Loading TF weight model/h6/ln_1/g with shape [768]\n","Loading TF weight model/h6/ln_2/b with shape [768]\n","Loading TF weight model/h6/ln_2/g with shape [768]\n","Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h7/attn/c_proj/b with shape [768]\n","Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h7/ln_1/b with shape [768]\n","Loading TF weight model/h7/ln_1/g with shape [768]\n","Loading TF weight model/h7/ln_2/b with shape [768]\n","Loading TF weight model/h7/ln_2/g with shape [768]\n","Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h8/attn/c_proj/b with shape [768]\n","Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h8/ln_1/b with shape [768]\n","Loading TF weight model/h8/ln_1/g with shape [768]\n","Loading TF weight model/h8/ln_2/b with shape [768]\n","Loading TF weight model/h8/ln_2/g with shape [768]\n","Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n","Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n","Loading TF weight model/h9/attn/c_proj/b with shape [768]\n","Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n","Loading TF weight model/h9/ln_1/b with shape [768]\n","Loading TF weight model/h9/ln_1/g with shape [768]\n","Loading TF weight model/h9/ln_2/b with shape [768]\n","Loading TF weight model/h9/ln_2/g with shape [768]\n","Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n","Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n","Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n","Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n","Loading TF weight model/ln_f/b with shape [768]\n","Loading TF weight model/ln_f/g with shape [768]\n","Loading TF weight model/wpe with shape [1024, 768]\n","Loading TF weight model/wte with shape [50257, 768]\n","Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h0', 'ln_1', 'b']\n","Initialize PyTorch weight ['h0', 'ln_1', 'g']\n","Initialize PyTorch weight ['h0', 'ln_2', 'b']\n","Initialize PyTorch weight ['h0', 'ln_2', 'g']\n","Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h1', 'ln_1', 'b']\n","Initialize PyTorch weight ['h1', 'ln_1', 'g']\n","Initialize PyTorch weight ['h1', 'ln_2', 'b']\n","Initialize PyTorch weight ['h1', 'ln_2', 'g']\n","Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h10', 'ln_1', 'b']\n","Initialize PyTorch weight ['h10', 'ln_1', 'g']\n","Initialize PyTorch weight ['h10', 'ln_2', 'b']\n","Initialize PyTorch weight ['h10', 'ln_2', 'g']\n","Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h11', 'ln_1', 'b']\n","Initialize PyTorch weight ['h11', 'ln_1', 'g']\n","Initialize PyTorch weight ['h11', 'ln_2', 'b']\n","Initialize PyTorch weight ['h11', 'ln_2', 'g']\n","Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h2', 'ln_1', 'b']\n","Initialize PyTorch weight ['h2', 'ln_1', 'g']\n","Initialize PyTorch weight ['h2', 'ln_2', 'b']\n","Initialize PyTorch weight ['h2', 'ln_2', 'g']\n","Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h3', 'ln_1', 'b']\n","Initialize PyTorch weight ['h3', 'ln_1', 'g']\n","Initialize PyTorch weight ['h3', 'ln_2', 'b']\n","Initialize PyTorch weight ['h3', 'ln_2', 'g']\n","Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h4', 'ln_1', 'b']\n","Initialize PyTorch weight ['h4', 'ln_1', 'g']\n","Initialize PyTorch weight ['h4', 'ln_2', 'b']\n","Initialize PyTorch weight ['h4', 'ln_2', 'g']\n","Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h5', 'ln_1', 'b']\n","Initialize PyTorch weight ['h5', 'ln_1', 'g']\n","Initialize PyTorch weight ['h5', 'ln_2', 'b']\n","Initialize PyTorch weight ['h5', 'ln_2', 'g']\n","Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h6', 'ln_1', 'b']\n","Initialize PyTorch weight ['h6', 'ln_1', 'g']\n","Initialize PyTorch weight ['h6', 'ln_2', 'b']\n","Initialize PyTorch weight ['h6', 'ln_2', 'g']\n","Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h7', 'ln_1', 'b']\n","Initialize PyTorch weight ['h7', 'ln_1', 'g']\n","Initialize PyTorch weight ['h7', 'ln_2', 'b']\n","Initialize PyTorch weight ['h7', 'ln_2', 'g']\n","Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h8', 'ln_1', 'b']\n","Initialize PyTorch weight ['h8', 'ln_1', 'g']\n","Initialize PyTorch weight ['h8', 'ln_2', 'b']\n","Initialize PyTorch weight ['h8', 'ln_2', 'g']\n","Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'b']\n","Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'w']\n","Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'b']\n","Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'w']\n","Initialize PyTorch weight ['h9', 'ln_1', 'b']\n","Initialize PyTorch weight ['h9', 'ln_1', 'g']\n","Initialize PyTorch weight ['h9', 'ln_2', 'b']\n","Initialize PyTorch weight ['h9', 'ln_2', 'g']\n","Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'b']\n","Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'w']\n","Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'b']\n","Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'w']\n","Initialize PyTorch weight ['ln_f', 'b']\n","Initialize PyTorch weight ['ln_f', 'g']\n","Initialize PyTorch weight ['wpe']\n","Initialize PyTorch weight ['wte']\n"],"name":"stderr"},{"output_type":"stream","text":["Save PyTorch model to aitextgen/pytorch_model.bin\n"],"name":"stdout"},{"output_type":"stream","text":["02/04/2021 03:54:19 — INFO — aitextgen — Loading 124M GPT-2 model from /aitextgen.\n"],"name":"stderr"},{"output_type":"stream","text":["Save configuration file to aitextgen/config.json\n"],"name":"stdout"},{"output_type":"stream","text":["02/04/2021 03:54:24 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"N8KXuKWzQSsN"},"source":["## Mounting Google Drive\n","\n","The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n","\n","Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"]},{"cell_type":"code","metadata":{"id":"puq4iC6vUAHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612410901788,"user_tz":-540,"elapsed":84882,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"cfc077dc-f961-477c-a73d-3070db92a388"},"source":["mount_gdrive()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJwKiefBTNi-","executionInfo":{"status":"ok","timestamp":1612410901790,"user_tz":-540,"elapsed":84880,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"45e3edc1-30fd-49d8-b33c-700ef5469769"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BT__brhBCvJu"},"source":["## Uploading a Text File to be Trained to Colaboratory\n","\n","In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n","\n","![alt text](https://i.imgur.com/w3wvHhR.png)\n","\n","Upload **any smaller text file** (for example, [a text file of Shakespeare plays](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)) and update the file name in the cell below, then run the cell."]},{"cell_type":"code","metadata":{"id":"6OFnPCLADfll"},"source":["# file_name = \"input.txt\"\r\n","# file_name = \"/content/drive/MyDrive/작사작곡_정리/작사/data/lyric_gpt2_518KB.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeeSKtNWUedE"},"source":["If your text file is large (>10MB), it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM.\n","\n","Additionally, you may want to consider [compressing the dataset to a cache first](https://docs.aitextgen.io/dataset/) on your local computer, then uploading the resulting `dataset_cache.tar.gz` and setting the `file_name`in the previous cell to that."]},{"cell_type":"code","metadata":{"id":"-Z6okFD8VKtS"},"source":["# copy_file_from_gdrive(file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LdpZQXknFNY3"},"source":["## Finetune GPT-2\n","\n","The next cell will start the actual finetuning of GPT-2 in aitextgen. It runs for `num_steps`, and a progress bar will appear to show training progress, current loss (the lower the better the model), and average loss (to give a sense on loss trajectory).\n","\n","The model will be saved every `save_every` steps in `trained_model` by default, and when training completes. If you mounted your Google Drive, the model will _also_ be saved there in a unique folder.\n","\n","The training might time out after 4ish hours; if you did not mount to Google Drive, make sure you end training and save the results so you don't lose them! (if this happens frequently, you may want to consider using [Colab Pro](https://colab.research.google.com/signup))\n","\n","Important parameters for `train()`:\n","\n","- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n","- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n","- **`num_steps`**: Number of steps to train the model for.\n","- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n","- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n","- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n","\n","Here are other important parameters for `train()` that are useful but you likely do not need to change.\n","\n","- **`learning_rate`**: Learning rate of the model training.\n","- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM."]},{"cell_type":"code","metadata":{"id":"aeXshJM-Cuaf"},"source":["# ai.train(file_name,\n","#          line_by_line=False,\n","#          from_cache=False,\n","#          num_steps=5000,\n","#          generate_every=1000,\n","#          save_every=1000,\n","#          save_gdrive=False,\n","#          learning_rate=1e-4,\n","#          batch_size=1, \n","#          )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qQJgV_b4bmzd"},"source":["You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."]},{"cell_type":"markdown","metadata":{"id":"pel-uBULXO2L"},"source":["\n","## Load a Trained Model\n","\n","Running the next cell will copy the `pytorch_model.bin` and the `config.json`file from the specified folder in Google Drive into the Colaboratory VM. (If no `from_folder` is specified, it assumes the two files are located at the root level of your Google Drive)"]},{"cell_type":"code","metadata":{"id":"DCcx5u7sbPTD"},"source":["# from_folder = None\n","\n","# for file in [\"pytorch_model.bin\", \"config.json\"]:\n","#   if from_folder:\n","#     copy_file_from_gdrive(file, from_folder)\n","#   else:\n","#     copy_file_from_gdrive(file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTa6zf3e_9gV"},"source":["The next cell will allow you to load the retrained model + metadata necessary to generate text."]},{"cell_type":"code","metadata":{"id":"-fxL77nvAMAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612410914344,"user_tz":-540,"elapsed":97388,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"3a79928a-2fb5-4dc7-91be-5a1c413917fe"},"source":["# ai = aitextgen(model=\"pytorch_model.bin\", config=\"config.json\", to_gpu=True)\r\n","pyt_model = \"/content/drive/MyDrive/작사작곡_정리/작사/result/20210114/pytorch_model.bin\"\r\n","conf = \"/content/drive/MyDrive/작사작곡_정리/작사/result/20210114/config.json\"\r\n","ai = aitextgen(model=pyt_model, config=conf, to_gpu=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["02/04/2021 03:55:02 — INFO — aitextgen — Loading GPT-2 model from provided /content/drive/MyDrive/작사작곡_정리/작사/result/20210114/pytorch_model.bin.\n","02/04/2021 03:55:14 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ClJwpF_ACONp"},"source":["## Generate Text From The Trained Model\n","\n","After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate()` without any parameters generates a single text from the loaded model to the console."]},{"cell_type":"code","metadata":{"id":"4RNY6RBI9LmL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612410918679,"user_tz":-540,"elapsed":101710,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"a78ed5c7-4fde-414c-d24b-61e42f379ab1"},"source":["ai.generate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1m\u001b[0m�에 앞으로 가자\r\n","우리들은 씩씩한 어린이라네\r\n","금수강산 이어받을 새싹이라네\r\n","하나 둘 셋 넷 앞으로 가자\r\n","두 주먹을 굳게 쥐고 앞으로 가자\r\n","우리들은 용감한 어린이라네\r\n","자유대한 길이 빛낼 새싹이라네\r\n","새들 노랫\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oF4-PqF0Fl7R"},"source":["If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = ai.generate_one()`\n","\n","You can also pass in a `prompt` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n","\n","You can also generate multiple texts at a time by specifing `n`. You can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 50 for `batch_size` to avoid going OOM).\n","\n","Other optional-but-helpful parameters for `ai.generate()` and friends:\n","\n","*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2, but it will be _much_ slower)\n","* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n","* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n","* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"]},{"cell_type":"code","metadata":{"id":"8DKMc0fiej4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612411709402,"user_tz":-540,"elapsed":3328,"user":{"displayName":"­민은영(엘텍공과대학 소프트웨어학부)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9zjmLL5FvJ6SS3ulh8G9-FN10WSIFCs86uMWn=s64","userId":"11223049352271749609"}},"outputId":"dda9892d-5311-422c-a04c-050686524435"},"source":["ai.generate(n=10,\n","            batch_size=5,\n","            prompt=\"동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \\n개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\",\n","            max_length=300,\n","            temperature=1.0,\n","            top_p=1.0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 소리\r\n","밤 하늘 별빛 반짝일때면 문득 생각이 나요\r\n","내가 쌓은 속에 파란 속에서 느껴져요\r\n","매일 아침 �\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m들\r\n","비단구두 사각사각 왔다가 반짝 꿈방울 속삭이면 수평선에 반짝이는 세상을 만들고 하늘까지 닿게\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 나누자.\r\n","빨간 꽃씨가 엄마가 웃음꽃이 활짝 웃는다고 잘잘 내게 춤춘다\r\n","비가 오면 떨어집니다 비가 �\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 소리\r\n","물결 넘어 앞에 내가 제일 좋아하는 우리 어린이\r\n","“어떻게 하면 어른이 될 수 있나요? 빨리 어린이�\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 소리\r\n","고요한 밤 거룩한 밤 어둠에 묻힌 밤\r\n","주의 부모 앉아서 감사 기도 드릴 때\r\n","아기 잘도 잔다 아기 �\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m를 들었지\r\n","동화속 나라 공잡했던 밤새 웃음소리 맴을도 하늘 보면 파란 산새들이 나뭇잎 손뼉치며 �\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 들려줍니다\r\n","\r\n","산도집도 아지는 산새소리 쪼로롱 꿈속에서 들려오고\r\n","쪼롱쪼로롱 산새소리에 산\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 송사리를 부르며 눈지요.\r\n","“아니? 내 발자국은 이렇게 생겼어. 누구인처럼 내 발자국을 따라가 봐야기\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m 들어와\r\n","아빠 손 잡고 노래하며 자라니까 아빠가 찾아오고 다람쥐 찾아 오늘 아빠의 얼굴에\r\n","파란 어�\n","==========\n","\u001b[1m동생과 함께 들판에 가서 강아지와 뛰어 놀면서 예쁜 꽃을 관찰한다. \n","개울가에서 송사리 잡다가 물놀이하느라 엄마가 찾는 소리에  집으로 가는 이야기\u001b[0m를 듣지요\r\n","머룩 눈파도 알려줘요 이제 모두 예쁘니 나도 친구 되게 그냥 지나가실거려요\r\n","꿈나가 �\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zjjEN2Tafhl2"},"source":["For bulk generation, you can generate a large amount of texts to a file and sort out the samples locally on your computer. The next cell will generate `num_files` files, each with `n` texts and whatever other parameters you would pass to `generate()`. The files can then be downloaded from the Files sidebar!\n","\n","You can rerun the cells as many times as you want for even more generated texts!"]},{"cell_type":"code","metadata":{"id":"Fa6p6arifSL0"},"source":["# num_files = 5\n","\n","# for _ in range(num_files):\n","#   ai.generate_to_file(n=1000,\n","#                      batch_size=50,\n","#                      prompt=\"ROMEO:\",\n","#                      max_length=256,\n","#                      temperature=1.0,\n","#                      top_p=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wmTXWNUygS5E"},"source":["# LICENSE\n","\n","MIT License\n","\n","Copyright (c) 2020 Max Woolf\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE."]}]}